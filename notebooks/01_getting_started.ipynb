{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disentangled Representation Learning\n",
    "\n",
    "Steps performed:\n",
    "1. Load Stable Diffusion model\n",
    "2. Generate or encode images\n",
    "3. Extract race vector\n",
    "4. Generate counterfactuals\n",
    "5. Evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models.stable_diffusion import StableDiffusionWrapper\n",
    "from src.latent.vector_discovery import RaceVectorExtractor\n",
    "from src.latent.manipulator import LatentManipulator\n",
    "from src.metrics.evaluator import CounterfactualEvaluator\n",
    "from src.visualization.grid_generator import CounterfactualGridGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = StableDiffusionWrapper(\n",
    "    device=device,\n",
    "    dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    enable_xformers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Test Images\n",
    "\n",
    "We'll generate a few images with different racial attributes to extract the race vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images with light skin tone\n",
    "light_images = []\n",
    "light_latents = []\n",
    "\n",
    "prompts_light = [\n",
    "    \"portrait photo of a person with light skin tone, professional headshot, neutral background\",\n",
    "    \"photo of a person with fair complexion, studio lighting\",\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts_light):\n",
    "    print(f\"Generating light skin image {i+1}/{len(prompts_light)}...\")\n",
    "    img, lat = model.generate_from_prompt(prompt, seed=42+i, num_inference_steps=30)\n",
    "    light_images.append(img)\n",
    "    light_latents.append(lat)\n",
    "\n",
    "# Generate images with dark skin tone\n",
    "dark_images = []\n",
    "dark_latents = []\n",
    "\n",
    "prompts_dark = [\n",
    "    \"portrait photo of a person with dark skin tone, professional headshot, neutral background\",\n",
    "    \"photo of a person with deep complexion, studio lighting\",\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts_dark):\n",
    "    print(f\"Generating dark skin image {i+1}/{len(prompts_dark)}...\")\n",
    "    img, lat = model.generate_from_prompt(prompt, seed=1042+i, num_inference_steps=30)\n",
    "    dark_images.append(img)\n",
    "    dark_latents.append(lat)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize generated images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "axes[0, 0].imshow(light_images[0])\n",
    "axes[0, 0].set_title(\"Light 1\")\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(light_images[1])\n",
    "axes[0, 1].set_title(\"Light 2\")\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(dark_images[0])\n",
    "axes[1, 0].set_title(\"Dark 1\")\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(dark_images[1])\n",
    "axes[1, 1].set_title(\"Dark 2\")\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Race Vector\n",
    "\n",
    "Compute the average difference between light and dark skin latent codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = RaceVectorExtractor(device=device)\n",
    "\n",
    "race_vector = extractor.extract_from_pairs(\n",
    "    light_latents,\n",
    "    dark_latents,\n",
    "    normalize=True,\n",
    ")\n",
    "\n",
    "print(f\"Race vector shape: {race_vector.shape}\")\n",
    "print(f\"Race vector norm: {race_vector.norm().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze vector properties\n",
    "from src.latent.vector_discovery import VectorAnalyzer\n",
    "\n",
    "analyzer = VectorAnalyzer(device=device)\n",
    "analysis = analyzer.analyze_spatial_pattern(race_vector)\n",
    "\n",
    "# Visualize spatial heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(analysis['spatial_heatmap'].cpu().numpy(), cmap='hot')\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.title('Race Vector Spatial Activation Pattern')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Height')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total magnitude: {analysis['total_magnitude']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Counterfactuals\n",
    "\n",
    "Apply the race vector to a new image at different magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate base image\n",
    "print(\"Generating base image...\")\n",
    "base_image, base_latent = model.generate_from_prompt(\n",
    "    \"portrait photo of a person, professional headshot, neutral background, high quality\",\n",
    "    seed=999,\n",
    "    num_inference_steps=30,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(base_image)\n",
    "plt.title(\"Base Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactuals at different alphas\n",
    "manipulator = LatentManipulator(device=device)\n",
    "\n",
    "alphas = [-2.0, -1.0, 0.0, 1.0, 2.0]\n",
    "\n",
    "print(\"Generating counterfactuals...\")\n",
    "counterfactual_latents = manipulator.generate_counterfactuals(\n",
    "    base_latent,\n",
    "    race_vector,\n",
    "    alphas,\n",
    ")\n",
    "\n",
    "# Decode to images\n",
    "counterfactual_images = []\n",
    "for lat in counterfactual_latents:\n",
    "    img = model.decode_latent(lat)\n",
    "    counterfactual_images.append(img)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize counterfactuals\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for i, (img, alpha) in enumerate(zip(counterfactual_images, alphas)):\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"α = {alpha:.1f}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Results\n",
    "\n",
    "Measure identity preservation and disentanglement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = CounterfactualEvaluator(device=device)\n",
    "\n",
    "# Evaluate each counterfactual (skip α=0)\n",
    "print(\"Evaluating counterfactuals...\\n\")\n",
    "\n",
    "results = []\n",
    "for i, (cf_image, alpha) in enumerate(zip(counterfactual_images, alphas)):\n",
    "    if abs(alpha) < 0.01:  # Skip original\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nEvaluating α = {alpha:.1f}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    result = evaluator.evaluate_pair(\n",
    "        base_image,\n",
    "        cf_image,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metrics\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([r.to_dict() for r in results])\n",
    "df['alpha'] = [a for a in alphas if abs(a) >= 0.01]\n",
    "\n",
    "# Plot metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Face similarity\n",
    "axes[0, 0].plot(df['alpha'], df['face_similarity'], 'o-')\n",
    "axes[0, 0].axhline(y=0.85, color='r', linestyle='--', label='Threshold')\n",
    "axes[0, 0].set_xlabel('Alpha')\n",
    "axes[0, 0].set_ylabel('Face Similarity')\n",
    "axes[0, 0].set_title('Identity Preservation')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Landmark RMSE\n",
    "if df['landmark_rmse'].notna().any():\n",
    "    axes[0, 1].plot(df['alpha'], df['landmark_rmse'], 'o-')\n",
    "    axes[0, 1].axhline(y=5.0, color='r', linestyle='--', label='Threshold')\n",
    "    axes[0, 1].set_xlabel('Alpha')\n",
    "    axes[0, 1].set_ylabel('Landmark RMSE (px)')\n",
    "    axes[0, 1].set_title('Facial Geometry Preservation')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "\n",
    "# Background SSIM\n",
    "if df['background_ssim'].notna().any():\n",
    "    axes[1, 0].plot(df['alpha'], df['background_ssim'], 'o-')\n",
    "    axes[1, 0].axhline(y=0.90, color='r', linestyle='--', label='Threshold')\n",
    "    axes[1, 0].set_xlabel('Alpha')\n",
    "    axes[1, 0].set_ylabel('Background SSIM')\n",
    "    axes[1, 0].set_title('Background Preservation')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "\n",
    "# Overall score\n",
    "axes[1, 1].plot(df['alpha'], df['overall_score'], 'o-')\n",
    "axes[1, 1].set_xlabel('Alpha')\n",
    "axes[1, 1].set_ylabel('Overall Score')\n",
    "axes[1, 1].set_title('Overall Disentanglement Quality')\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Visualization Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = CounterfactualGridGenerator()\n",
    "\n",
    "# Create grid (excluding α=0)\n",
    "cf_images_no_orig = [img for img, a in zip(counterfactual_images, alphas) if abs(a) >= 0.01]\n",
    "labels = [f\"α={a:.1f}\" for a in alphas if abs(a) >= 0.01]\n",
    "metrics_list = [r.to_dict() for r in results]\n",
    "\n",
    "grid = generator.generate_grid(\n",
    "    base_image,\n",
    "    cf_images_no_orig,\n",
    "    labels=labels,\n",
    "    metrics=metrics_list,\n",
    "    title=\"Disentangled Race Vector Demonstration\",\n",
    ")\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Save\n",
    "grid.save('../experiments/results/demo_grid.png')\n",
    "print(\"Grid saved to: experiments/results/demo_grid.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "Completed steps:\n",
    "1. Extracted a race vector from paired examples\n",
    "2. Applied the vector to generate counterfactuals\n",
    "3. Evaluated identity preservation metrics\n",
    "4. Created visualization grids\n",
    "\n",
    "To do:\n",
    "- Perform with real images\n",
    "- Optimize race vector \n",
    "- Full experiments with \n",
    "- Ablation studies "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
